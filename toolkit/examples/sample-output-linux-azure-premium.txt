╔════════════════════════════════════════════════════════════╗
║   Docker Performance & Security Analysis Toolkit           ║
║   Deep-dive companion for container optimization           ║
╚════════════════════════════════════════════════════════════╝


\033[0;34mWhat this toolkit does:\033[0m
Exposes how Linux kernel primitives (namespaces, cgroups, OverlayFS)
shape container performance, security, and operational characteristics.

\033[0;34mWhat this toolkit is NOT:\033[0m
• NOT a storage benchmark suite (use fio/iozone for that)
• NOT a comprehensive security scanner (use trivy/grype for that)
• NOT a production monitoring tool (use Prometheus/Datadog for that)

\033[0;34mUse this to:\033[0m
• Understand platform-specific container behavior
• Establish baseline performance characteristics
• Validate that Docker primitives work as expected
• Identify optimization opportunities (volumes vs OverlayFS, etc.)


========================================
Checking Prerequisites
========================================

✓ docker found: Docker version 29.1.3, build f52814d
✓ strace found
✓ perf found
⚠ jq not found (optional for JSON parsing)
⚠ bpftrace not found (optional for eBPF tracing)

========================================
Test 1: Container Startup Latency
========================================

Untagged: alpine:latest
Deleted: sha256:865b95f46d98cf867a156fe4a135ad3fe50d2056aa3f25ed31662dff6da4eb62
=== Phase 1: Image Pull (network + extraction) ===
Image pull time: 824ms

=== Phase 2: Container Runtime (namespace + exec) ===
Measuring first run (cold - may include overlay setup)...
Cold start (no pull): 488ms

Measuring warm start (cached layers)...
Warm start (cached): 542ms

=== Phase 3: Average Runtime (10 iterations) ===
Average startup time: 496ms

=== Decomposition Summary ===
Pull + extraction: 824ms (network + registry)
Runtime overhead:  496ms (namespace + exec)
Total cold start:  1312ms

The 496ms runtime overhead reflects Docker's architecture on this platform.
This includes: namespace creation (~5ms), OverlayFS mount, cgroup setup (~3ms),
and platform-specific operations (containerd shim, managed disk metadata).
On bare metal or optimized runtimes, this overhead is typically 100-200ms.
Runtime: 496ms
Note: Container startup includes namespace creation, OverlayFS mount,
cgroup setup, and storage I/O. Cloud environments typically show 300-700ms
due to the combination of kernel operations and storage layer interactions.

========================================
Test 2: Container Process Hierarchy & Syscall Overview
========================================

=== Docker Component Architecture ===
Starting test container to observe process tree...

Docker daemon process:
root        2690  0.1  0.8 1941796 70064 ?       Ssl  15:40   0:11 /usr/bin/containerd
root        2849  0.2  1.5 2122120 125400 ?      Ssl  15:40   0:12 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
root       19579  0.0  0.1 1233584 12768 ?       Sl   17:19   0:00 /usr/bin/containerd-shim-runc-v2 -namespace moby -id 0357bf7b3b731dad8cef5083d5b1120f75e6d95d458aae46d3d1b344a7ca6d62 -address /run/containerd/containerd.sock

Container process hierarchy:
Container PID: 19602

Process details:
UID          PID    PPID  C STIME TTY          TIME CMD
root       19602   19579  0 17:19 ?        00:00:00 sleep 60

Parent process chain:
    PID    PPID COMMAND
  19602   19579 sleep

Namespace IDs (proves isolation exists):
lrwxrwxrwx 1 root root 0 Dec 30 17:19 mnt -> mnt:[4026532154]
lrwxrwxrwx 1 root root 0 Dec 30 17:19 net -> net:[4026532160]
lrwxrwxrwx 1 root root 0 Dec 30 17:19 pid -> pid:[4026532158]
lrwxrwxrwx 1 root root 0 Dec 30 17:19 pid_for_children -> pid:[4026532158]

=== Syscall Tracing Attempt ===
Note: Tracing container creation syscalls requires attaching to containerd/runc
Attempting basic trace of docker CLI (limited visibility)...
traced

Syscalls from docker CLI process:
  execve() calls: 1 (CLI launching processes)

Note: Container namespace creation happens in containerd/runc,
not in the docker CLI. To trace actual namespace syscalls, use:
  sudo strace -fp $(pidof containerd) -e trace=clone,unshare,mount

Trace file saved: /tmp/docker-syscall-trace.log

Limitation: Full syscall visibility requires privileged tracing of
container runtime components (dockerd/containerd/runc), which varies by platform.

========================================
Test 3: OverlayFS Layer Analysis
========================================

Pulling multi-layer image (nginx)...

Image layers:
            "Layers": [
                "sha256:7bb20cf5ef67526cb843d264145241ce4dde09a337b5be1be42ba464de9a672d",
                "sha256:fd1e40d7f74b5c12a5d7cd010e7c978719bcc364b758e951b729d6e97469f3f9",
                "sha256:48078b7e3000f40c4d67cb908f5bb56a322b757f7ccdf09794a109317da7a37a",
                "sha256:b3e3d1bbb64d1d10e26662b1f8528f1afd0271b85edcd2d8371d09fc0a606dba",
                "sha256:8ae63eb1f31f3155ef6ccdc63d777602944e975b9a6c38909257c62a623dee60",
                "sha256:ed5fa8595c7aa2584655c40c2835c75fc0c2039f72a2dac993442a4d19a7266b",
                "sha256:67ea0b046e7d3167953e9b192b7fb23be8ad6c026e65294b7070583e68fe5807",
                "sha256:e6fe11fa5b7f250edfbaca239d0f043e0d825c52a9809d13dd928a1ece6a3742"
            ]
        },
        "Metadata": {
            "LastTagTime": "2025-12-30T17:19:33.24808565Z"
        },
        "Descriptor": {
            "mediaType": "application/vnd.oci.image.index.v1+json",
            "digest": "sha256:8491795299c8e739b7fcc6285d531d9812ce2666e07bd3dd8db00020ad132295",
            "size": 10333
        }
    }
]

Physical layer storage:
Image ID: 8491795299c8e739b7fcc6285d531d9812ce2666e07bd3dd8db00020ad132295
⚠ /var/lib/docker/overlay2 not accessible (may require root)

========================================
Test 4: I/O Performance Analysis
========================================

=== Sequential Write Performance ===
Testing container filesystem (OverlayFS upper layer)...
104857600 bytes (100.0MB) copied, 0.271779 seconds, 367.9MB/s

Testing with volume mount (bypasses OverlayFS)...
104857600 bytes (100.0MB) copied, 0.770383 seconds, 129.8MB/s

Note on I/O Results:
Sequential write throughput varies based on multiple factors:
• Storage backend (OverlayFS upper dir vs volume mount path)
• Disk caching policies (write-through vs write-back)
• Filesystem layer (ext4, xfs, tmpfs backing)
• Managed disk caching modes (in cloud environments)
• Durability guarantees (volume test includes fsync for data safety)

Key takeaway: Volumes provide CONSISTENCY and bypass OverlayFS copy-up,
not necessarily higher raw sequential throughput. For write-heavy workloads
behavioral differences in write handling, not raw performance parity.

=== OverlayFS Copy-up Overhead ===
Creating container with pre-existing 100MB file...
-rw-r--r--    1 root     root      100.0M Dec 30 17:19 /bigfile
Triggering copy-up by modifying file in read-only layer...
Copy-up operation time: 67ms

Analysis: Copy-up overhead <100ms - acceptable for this file size.

=== OverlayFS vs Volume: Metadata Operations ===
Testing metadata-heavy workload (file creation patterns)...
OverlayFS (container filesystem):
  500 file creates: 796ms
Volume mount (direct filesystem):
  500 file creates: 734ms

OverlayFS metadata overhead: 62ms (796ms vs 734ms)
OverlayFS shows 8% overhead - sensitivity to metadata patterns.
Impact depends on workload characteristics and file operation frequency.

Note: Metadata operation overhead varies significantly with:
• Number of files (tested: 500 files, increase to 5000+ for heavier pressure)
• Directory depth (nested directories amplify overhead)
• Operation mix (create vs delete vs rename)

========================================
Test 5: Network Performance
========================================

=== Network Connectivity Verification ===
Testing bridge network connectivity...
10 packets transmitted, 10 packets received, 0% packet loss

Testing host network connectivity...
10 packets transmitted, 10 packets received, 0% packet loss

Note: This is a connectivity sanity check, not a performance benchmark.
For actual network performance analysis, use tools like iperf3 or netperf.

Network overhead comparison:
• Bridge mode: Adds veth pair + iptables NAT (~0.1-0.3ms latency)
• Host mode: Direct host network stack (minimal overhead)
• For latency-critical services: Consider host networking
• For isolation: Use bridge networking (standard)

========================================
Test 6: Memory Efficiency & Page Cache Sharing
========================================

Starting 3 identical nginx containers...

Individual container memory usage:
NAME      MEM USAGE / LIMIT     MEM %
nginx1    3.234MiB / 7.709GiB   0.04%
nginx2    3.23MiB / 7.709GiB    0.04%
nginx3    3.25MiB / 7.709GiB    0.04%

Physical memory (RSS) per container:
nginx1 (PID 21598):  5888 KB
nginx2 (PID 21689):  6144 KB
nginx3 (PID 21777):  5888 KB

Note: Shared pages (like nginx binary) are counted once in physical memory
Total reported may exceed actual RAM usage due to page cache sharing

========================================
Test 7: Security Posture Analysis
========================================

Checking default container capabilities...
CapInh:	0000000000000000
CapPrm:	00000000a80425fb
CapEff:	00000000a80425fb
CapBnd:	00000000a80425fb
CapAmb:	0000000000000000

Capability names (requires libcap):
0x00000000a80425fb=cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_sys_chroot,cap_mknod,cap_audit_write,cap_setfcap

Testing restricted container (no capabilities):
CapInh:	0000000000000000
CapPrm:	0000000000000000
CapEff:	0000000000000000
CapBnd:	0000000000000000
CapAmb:	0000000000000000

Checking for privileged containers (security risk):
✓ No privileged containers running

Checking Docker socket mounts (security risk):
✓ No containers with Docker socket access

========================================
Test 8: CPU Performance & Throttling
========================================

=== CPU Usage Without Limits ===
Starting CPU-intensive container (infinite loop)...
CPU usage:
NAME       CPU %
cpu-test   99.17%

=== CPU Throttling Test (50% of 1 core) ===
Starting CPU-limited container...
CPU usage (target: 50.00%):
Measured: 50.12%
Throttling accuracy: 100%
✓ Excellent cgroup enforcement (<1% variance)

Analysis: CPU cgroups provide deterministic resource isolation.
This is a kernel-level guarantee, platform-invariant across infrastructure.

========================================
Test 9: Namespace Isolation Inspection
========================================

Starting test container...
Container PID: 22603

Namespace links for container process:
total 0
lrwxrwxrwx 1 root root 0 Dec 30 17:20 cgroup -> cgroup:[4026532159]
lrwxrwxrwx 1 root root 0 Dec 30 17:20 ipc -> ipc:[4026532156]
lrwxrwxrwx 1 root root 0 Dec 30 17:20 mnt -> mnt:[4026532154]
lrwxrwxrwx 1 root root 0 Dec 30 17:20 net -> net:[4026532160]
lrwxrwxrwx 1 root root 0 Dec 30 17:20 pid -> pid:[4026532158]
lrwxrwxrwx 1 root root 0 Dec 30 17:20 pid_for_children -> pid:[4026532158]
lrwxrwxrwx 1 root root 0 Dec 30 17:20 time -> time:[4026531834]
lrwxrwxrwx 1 root root 0 Dec 30 17:20 time_for_children -> time:[4026531834]
lrwxrwxrwx 1 root root 0 Dec 30 17:20 user -> user:[4026531837]
lrwxrwxrwx 1 root root 0 Dec 30 17:20 uts -> uts:[4026532155]

Comparing to host namespaces:
Host PID namespace:
lrwxrwxrwx 1 root root 0 Dec 30 15:40 /proc/1/ns/pid -> pid:[4026531836]
Container PID namespace:
lrwxrwxrwx 1 root root 0 Dec 30 17:20 /proc/22603/ns/pid -> pid:[4026532158]

Container's view of processes (should only see itself):
PID   USER     TIME  COMMAND
    1 root      0:00 sleep 60
    7 root      0:00 ps aux

========================================
Test 10: eBPF-based Syscall Tracing (Advanced)
========================================

⚠ bpftrace not available, skipping

========================================
Performance Analysis Summary
========================================

Docker daemon info:
 Storage Driver: overlayfs
 Kernel Version: 6.8.0-1044-azure
 Operating System: Ubuntu 22.04.5 LTS
 CPUs: 2
 Total Memory: 7.709GiB

Analysis complete!

Key findings:
1. Startup latency varies by environment:
   • Local development (NVMe SSD, warm cache): 100-200ms typical
   • Cloud Premium SSD: 200-500ms typical
   • Cloud Standard HDD: 500-800ms typical
   Your environment determines expectations.
2. OverlayFS copy-up operations add latency for large file modifications
3. Use volumes for write-heavy workloads to bypass storage driver
4. Host networking reduces latency by ~0.2ms but sacrifices isolation
5. Page cache sharing makes multiple identical containers memory-efficient
6. Avoid privileged containers and Docker socket mounts in production

Recommendations:
• Use multi-stage builds to reduce image size
• Minimize layer count (combine RUN commands)
• Drop unnecessary capabilities (--cap-drop=ALL)
• Set resource limits (--memory, --cpus) for production
• Use read-only root filesystem where possible (--read-only)
• Enable user namespace remapping for additional security

All tests completed!
Logs and traces saved in /tmp/
